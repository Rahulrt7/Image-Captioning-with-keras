{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.coco_utils import load_coco_data\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Activation, TimeDistributed, Merge\n",
    "from keras.layers import Embedding, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import RepeatVector\n",
    "from keras import callbacks, utils, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading the data to Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_to_word <type 'list'> 1004\n",
      "train_captions <type 'numpy.ndarray'> (400135, 17) int32\n",
      "val_captions <type 'numpy.ndarray'> (195954, 17) int32\n",
      "train_image_idxs <type 'numpy.ndarray'> (400135,) int32\n",
      "val_features <type 'numpy.ndarray'> (40504, 512) float32\n",
      "val_image_idxs <type 'numpy.ndarray'> (195954,) int32\n",
      "train_features <type 'numpy.ndarray'> (82783, 512) float32\n",
      "train_urls <type 'numpy.ndarray'> (82783,) |S63\n",
      "val_urls <type 'numpy.ndarray'> (40504,) |S63\n",
      "word_to_idx <type 'dict'> 1004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = load_coco_data(pca_features=True)\n",
    "\n",
    "# Print out all the keys and values from the data dictionary\n",
    "for k, v in data.iteritems():\n",
    "  if type(v) == np.ndarray:\n",
    "    print k, type(v), v.shape, v.dtype\n",
    "  else:\n",
    "    print k, type(v), len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_captions_mat = data['train_captions']\n",
    "train_image_idxs = data['train_image_idxs']\n",
    "train_features = data['train_features']\n",
    "val_captions_mat = data['val_captions']\n",
    "val_image_idxs = data['val_image_idxs']\n",
    "val_features = data['val_features']\n",
    "idx_to_word = data['idx_to_word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://farm8.staticflickr.com/7003/6528937031_10e1ce0960_z.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=  data['val_image_idxs'][3]\n",
    "b = data['val_urls'][a]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   4 142 510  10 667 415 277  58   2   0   0   0   0   0   0   0]\n",
      "<START> a very clean and well decorated empty bathroom <END> <NULL> <NULL> <NULL> <NULL> <NULL> <NULL> <NULL>\n"
     ]
    }
   ],
   "source": [
    "print train_captions_mat[0]\n",
    "for i in train_captions_mat[0]:\n",
    "    print idx_to_word[i],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Number of images to use for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "limit1 = len(train_image_idxs)\n",
    "limit2 = len(val_image_idxs)\n",
    "num_train_img = limit1\n",
    "num_val_img = limit2\n",
    "num_train_cap = limit1\n",
    "num_val_cap = limit2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Constructng image_train and image_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_train = np.zeros((num_train_img, 512))\n",
    "image_val = np.zeros((num_val_img, 512))\n",
    "for i in range(num_train_img):\n",
    "    index = train_image_idxs[i]\n",
    "    image_train[i] = train_features[index]\n",
    "    \n",
    "for i in range(num_val_img):\n",
    "    index = val_image_idxs[i]\n",
    "    image_val[i] = val_features[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400135, 512) (195954, 512)\n"
     ]
    }
   ],
   "source": [
    "print image_train.shape, image_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Construct word_train and word_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400135, 17) (195954, 17)\n"
     ]
    }
   ],
   "source": [
    "word_train = train_captions_mat[:num_train_cap]\n",
    "word_val = val_captions_mat[:num_val_cap]\n",
    "print word_train.shape, word_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Constructing one-hot ecodings for y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_train = np.zeros((num_train_img, 17, 1004))\\ny_val = np.zeros((num_val_img, 17, 1004))\\n\\nfor i in range(num_train_img):\\n    for j in range(17):\\n        y_train[i][j] = utils.to_categorical(train_captions_mat[i][j], 1004)\\n        \\nfor i in range(num_val_img):\\n    for j in range(17):\\n        y_val[i][j] = utils.to_categorical(val_captions_mat[i][j], 1004)\\n\\nprint y_train.shape, y_val.shape\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "y_train = np.zeros((num_train_img, 17, 1004))\n",
    "y_val = np.zeros((num_val_img, 17, 1004))\n",
    "\n",
    "for i in range(num_train_img):\n",
    "    for j in range(17):\n",
    "        y_train[i][j] = utils.to_categorical(train_captions_mat[i][j], 1004)\n",
    "        \n",
    "for i in range(num_val_img):\n",
    "    for j in range(17):\n",
    "        y_val[i][j] = utils.to_categorical(val_captions_mat[i][j], 1004)\n",
    "\n",
    "print y_train.shape, y_val.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sparse encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   4 142 510  10 667 415 277  58   2   0   0   0   0   0   0   0]\n",
      "(400135, 17)\n"
     ]
    }
   ],
   "source": [
    "print train_captions_mat[0]\n",
    "print train_captions_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400135, 17, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.zeros((num_train_img, 17, 1))\n",
    "y_val = np.zeros((num_val_img, 17, 1))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(num_train_img):\n",
    "    for j in range(17):\n",
    "        y_train[i][j] = train_captions_mat[i][j]\n",
    "        \n",
    "for i in range(num_val_img):\n",
    "    for j in range(17):\n",
    "        y_val[i][j] = val_captions_mat[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(num_train_img):\\n    for j in range(16):\\n        y_train[i][j] = y_train[i][j+1]\\n    \\nfor i in range(num_val_img):\\n    for j in range(16):\\n        y_val[i][j] = y_val[i][j+1]\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shifting values one bit left\n",
    "\"\"\"\n",
    "for i in range(num_train_img):\n",
    "    for j in range(16):\n",
    "        y_train[i][j] = y_train[i][j+1]\n",
    "    \n",
    "for i in range(num_val_img):\n",
    "    for j in range(16):\n",
    "        y_val[i][j] = y_val[i][j+1]\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1.]\n",
      " [   4.]\n",
      " [ 142.]\n",
      " [  29.]\n",
      " [  58.]\n",
      " [   9.]\n",
      " [   3.]\n",
      " [ 257.]\n",
      " [  36.]\n",
      " [   2.]\n",
      " [   0.]\n",
      " [   0.]\n",
      " [   0.]\n",
      " [   0.]\n",
      " [   0.]\n",
      " [   0.]\n",
      " [   0.]]\n",
      "[  1   4 142  29  58   9   3 257  36   2   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print y_train[1000]\n",
    "print train_captions_mat[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400135, 17, 1) (195954, 17, 1)\n"
     ]
    }
   ],
   "source": [
    "print y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print len(y_train[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Feeding input into the model to fit sentence by sentence in a LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blank/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:21: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_1 (Merge)              (None, 17, 1024)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 17, 512)           3147776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 17, 1004)          515052    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 1004)          0         \n",
      "=================================================================\n",
      "Total params: 4,439,532.0\n",
      "Trainable params: 4,439,532.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "129s - loss: 4.3500 - acc: 0.3005\n",
      "Epoch 2/100\n",
      "128s - loss: 3.6040 - acc: 0.3718\n",
      "Epoch 3/100\n",
      "128s - loss: 3.1725 - acc: 0.4276\n",
      "Epoch 4/100\n",
      "128s - loss: 2.9574 - acc: 0.4722\n",
      "Epoch 5/100\n",
      "128s - loss: 2.7360 - acc: 0.5094\n",
      "Epoch 6/100\n",
      "128s - loss: 2.5626 - acc: 0.5329\n",
      "Epoch 7/100\n",
      "128s - loss: 2.4448 - acc: 0.5566\n",
      "Epoch 8/100\n",
      "128s - loss: 2.3567 - acc: 0.5718\n",
      "Epoch 9/100\n",
      "128s - loss: 2.2769 - acc: 0.5858\n",
      "Epoch 10/100\n",
      "128s - loss: 2.1848 - acc: 0.6079\n",
      "Epoch 11/100\n",
      "128s - loss: 2.0801 - acc: 0.6330\n",
      "Epoch 12/100\n",
      "128s - loss: 1.9895 - acc: 0.6496\n",
      "Epoch 13/100\n",
      "128s - loss: 1.9162 - acc: 0.6617\n",
      "Epoch 14/100\n",
      "129s - loss: 1.8499 - acc: 0.6730\n",
      "Epoch 15/100\n",
      "128s - loss: 1.7913 - acc: 0.6830\n",
      "Epoch 16/100\n",
      "129s - loss: 1.7403 - acc: 0.6911\n",
      "Epoch 17/100\n",
      "128s - loss: 1.6950 - acc: 0.6982\n",
      "Epoch 18/100\n",
      "128s - loss: 1.6543 - acc: 0.7044\n",
      "Epoch 19/100\n",
      "128s - loss: 1.6176 - acc: 0.7098\n",
      "Epoch 20/100\n",
      "129s - loss: 1.5830 - acc: 0.7150\n",
      "Epoch 21/100\n",
      "139s - loss: 1.5511 - acc: 0.7200\n",
      "Epoch 22/100\n",
      "136s - loss: 1.5207 - acc: 0.7249\n",
      "Epoch 23/100\n",
      "136s - loss: 1.4914 - acc: 0.7299\n",
      "Epoch 24/100\n",
      "136s - loss: 1.4630 - acc: 0.7351\n",
      "Epoch 25/100\n",
      "129s - loss: 1.4352 - acc: 0.7402\n",
      "Epoch 26/100\n",
      "136s - loss: 1.4078 - acc: 0.7454\n",
      "Epoch 27/100\n",
      "130s - loss: 1.3809 - acc: 0.7505\n",
      "Epoch 28/100\n",
      "133s - loss: 1.3550 - acc: 0.7553\n",
      "Epoch 29/100\n",
      "132s - loss: 1.3295 - acc: 0.7601\n",
      "Epoch 30/100\n",
      "137s - loss: 1.3046 - acc: 0.7648\n",
      "Epoch 31/100\n",
      "134s - loss: 1.2804 - acc: 0.7693\n",
      "Epoch 32/100\n",
      "129s - loss: 1.2570 - acc: 0.7736\n",
      "Epoch 33/100\n",
      "131s - loss: 1.2347 - acc: 0.7776\n",
      "Epoch 34/100\n",
      "129s - loss: 1.2123 - acc: 0.7818\n",
      "Epoch 35/100\n",
      "129s - loss: 1.1910 - acc: 0.7856\n",
      "Epoch 36/100\n",
      "134s - loss: 1.1701 - acc: 0.7895\n",
      "Epoch 37/100\n",
      "138s - loss: 1.1499 - acc: 0.7933\n",
      "Epoch 38/100\n",
      "137s - loss: 1.1300 - acc: 0.7968\n",
      "Epoch 39/100\n",
      "138s - loss: 1.1109 - acc: 0.8002\n",
      "Epoch 40/100\n",
      "137s - loss: 1.0919 - acc: 0.8036\n",
      "Epoch 41/100\n",
      "128s - loss: 1.0735 - acc: 0.8069\n",
      "Epoch 42/100\n",
      "129s - loss: 1.0558 - acc: 0.8100\n",
      "Epoch 43/100\n",
      "128s - loss: 1.0381 - acc: 0.8132\n",
      "Epoch 44/100\n",
      "128s - loss: 1.0211 - acc: 0.8161\n",
      "Epoch 45/100\n",
      "128s - loss: 1.0045 - acc: 0.8192\n",
      "Epoch 46/100\n",
      "128s - loss: 0.9884 - acc: 0.8220\n",
      "Epoch 47/100\n",
      "128s - loss: 0.9726 - acc: 0.8247\n",
      "Epoch 48/100\n",
      "128s - loss: 0.9572 - acc: 0.8274\n",
      "Epoch 49/100\n",
      "128s - loss: 0.9421 - acc: 0.8302\n",
      "Epoch 50/100\n",
      "128s - loss: 0.9273 - acc: 0.8328\n",
      "Epoch 51/100\n",
      "128s - loss: 0.9128 - acc: 0.8354\n",
      "Epoch 52/100\n",
      "128s - loss: 0.8987 - acc: 0.8379\n",
      "Epoch 53/100\n",
      "128s - loss: 0.8851 - acc: 0.8404\n",
      "Epoch 54/100\n",
      "128s - loss: 0.8715 - acc: 0.8428\n",
      "Epoch 55/100\n",
      "128s - loss: 0.8584 - acc: 0.8452\n",
      "Epoch 56/100\n",
      "128s - loss: 0.8456 - acc: 0.8474\n",
      "Epoch 57/100\n",
      "128s - loss: 0.8327 - acc: 0.8498\n",
      "Epoch 58/100\n",
      "128s - loss: 0.8204 - acc: 0.8521\n",
      "Epoch 59/100\n",
      "128s - loss: 0.8085 - acc: 0.8543\n",
      "Epoch 60/100\n",
      "132s - loss: 0.7966 - acc: 0.8566\n",
      "Epoch 61/100\n",
      "133s - loss: 0.7851 - acc: 0.8587\n",
      "Epoch 62/100\n",
      "130s - loss: 0.7740 - acc: 0.8608\n",
      "Epoch 63/100\n",
      "130s - loss: 0.7629 - acc: 0.8629\n",
      "Epoch 64/100\n",
      "131s - loss: 0.7519 - acc: 0.8649\n",
      "Epoch 65/100\n",
      "128s - loss: 0.7416 - acc: 0.8668\n",
      "Epoch 66/100\n",
      "128s - loss: 0.7313 - acc: 0.8687\n",
      "Epoch 67/100\n",
      "128s - loss: 0.7209 - acc: 0.8708\n",
      "Epoch 68/100\n",
      "128s - loss: 0.7112 - acc: 0.8726\n",
      "Epoch 69/100\n",
      "128s - loss: 0.7015 - acc: 0.8744\n",
      "Epoch 70/100\n",
      "128s - loss: 0.6921 - acc: 0.8762\n",
      "Epoch 71/100\n",
      "128s - loss: 0.6828 - acc: 0.8780\n",
      "Epoch 72/100\n",
      "128s - loss: 0.6738 - acc: 0.8796\n",
      "Epoch 73/100\n",
      "129s - loss: 0.6647 - acc: 0.8815\n",
      "Epoch 74/100\n",
      "128s - loss: 0.6563 - acc: 0.8830\n",
      "Epoch 75/100\n",
      "128s - loss: 0.6475 - acc: 0.8847\n",
      "Epoch 76/100\n",
      "129s - loss: 0.6393 - acc: 0.8862\n",
      "Epoch 77/100\n",
      "128s - loss: 0.6308 - acc: 0.8878\n",
      "Epoch 78/100\n",
      "128s - loss: 0.6229 - acc: 0.8894\n",
      "Epoch 79/100\n",
      "128s - loss: 0.6151 - acc: 0.8908\n",
      "Epoch 80/100\n",
      "128s - loss: 0.6071 - acc: 0.8924\n",
      "Epoch 81/100\n",
      "128s - loss: 0.5999 - acc: 0.8937\n",
      "Epoch 82/100\n",
      "128s - loss: 0.5925 - acc: 0.8951\n",
      "Epoch 83/100\n",
      "128s - loss: 0.5852 - acc: 0.8964\n",
      "Epoch 84/100\n",
      "128s - loss: 0.5780 - acc: 0.8978\n",
      "Epoch 85/100\n",
      "128s - loss: 0.5711 - acc: 0.8990\n",
      "Epoch 86/100\n",
      "128s - loss: 0.5641 - acc: 0.9004\n",
      "Epoch 87/100\n",
      "128s - loss: 0.5576 - acc: 0.9016\n",
      "Epoch 88/100\n",
      "129s - loss: 0.5507 - acc: 0.9029\n",
      "Epoch 89/100\n",
      "129s - loss: 0.5442 - acc: 0.9041\n",
      "Epoch 90/100\n",
      "130s - loss: 0.5378 - acc: 0.9053\n",
      "Epoch 91/100\n",
      "129s - loss: 0.5317 - acc: 0.9064\n",
      "Epoch 92/100\n",
      "129s - loss: 0.5254 - acc: 0.9076\n",
      "Epoch 93/100\n",
      "131s - loss: 0.5193 - acc: 0.9087\n",
      "Epoch 94/100\n",
      "130s - loss: 0.5135 - acc: 0.9098\n",
      "Epoch 95/100\n",
      "131s - loss: 0.5075 - acc: 0.9109\n",
      "Epoch 96/100\n",
      "130s - loss: 0.5020 - acc: 0.9119\n",
      "Epoch 97/100\n",
      "128s - loss: 0.4962 - acc: 0.9130\n",
      "Epoch 98/100\n",
      "128s - loss: 0.4908 - acc: 0.9139\n",
      "Epoch 99/100\n",
      "128s - loss: 0.4854 - acc: 0.9149\n",
      "Epoch 100/100\n",
      "128s - loss: 0.4800 - acc: 0.9158\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vector_length = 512\n",
    "vocabulary_size = 1004\n",
    "max_caption_length = 17\n",
    "batch_size = 128             # one parameter update per sentence\n",
    "image_vector_length = 512\n",
    "\n",
    "# image vector\n",
    "image_model = Sequential()\n",
    "image_model.add(Dense(image_vector_length, input_dim=512))\n",
    "image_model.add(RepeatVector(max_caption_length))\n",
    "\n",
    "# caption vector\n",
    "word_model = Sequential()\n",
    "word_model.add(Embedding(input_dim=vocabulary_size, \n",
    "                    output_dim=embedding_vector_length, input_length=17))\n",
    "\n",
    "# Merge models\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([image_model, word_model], mode='concat'))  # merging layers\n",
    "\n",
    "model.add(LSTM(512, input_shape=(17,512), unroll=True, return_sequences=True, implementation=2, stateful=False))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(TimeDistributed(Dense(vocabulary_size)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "# path to checkpoints\n",
    "filepath = './checkpoints/weights-{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_acc', save_best_only=True, verbose=0, mode='max')\n",
    "board = callbacks.TensorBoard(log_dir='./tensorboard_logs', histogram_freq=5, write_graph=True, write_images=True)\n",
    "\n",
    "\n",
    "model_history = model.fit([image_train, word_train], y_train, verbose=2,\n",
    "                              batch_size=batch_size, shuffle=True, epochs=100)\n",
    "\n",
    "score = model.evaluate([image_val, word_val], y_val, verbose=2, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44071341010851289, 0.92489414288479654]\n"
     ]
    }
   ],
   "source": [
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   4,  42,  51,  11, 160,   4,  22,  83,   2,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_classes([image_val[:29], word_val[:29]], verbose=2)[27]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "actual = val_captions_mat[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def arr_to_sent(predicted, actual):\n",
    "    s = []\n",
    "    m = data['idx_to_word']\n",
    "    for i in predicted:\n",
    "        s.append(m[i])\n",
    "    print \" \".join(s)\n",
    "    s = []\n",
    "    for i in actual:\n",
    "        s.append(m[i])\n",
    "    print \" \".join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> a black cat is inside a white toilet <END> <NULL> <NULL> <NULL> <NULL> <NULL> <NULL> <NULL>\n",
      "<START> a black cat is inside a white toilet <END> <NULL> <NULL> <NULL> <NULL> <NULL> <NULL> <NULL>\n"
     ]
    }
   ],
   "source": [
    "arr_to_sent(prediction, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
